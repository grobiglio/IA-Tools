[Inicio](./README.md) | [Anterior (1. Markdown)](./1-Markdown.md) | [PrÃ³ximo (3. IngenierÃ­a de Prompts)](./3-IngPrompts.md)

---

# Fundamentos de ChatGPT y conceptos clave

**Objetivo**: Comprender cÃ³mo funciona ChatGPT, su estructura y los conceptos esenciales para interactuar eficazmente.

## Ãndice de contenidos

- [IntroducciÃ³n a ChatGPT](#introducciÃ³n-a-chatgpt)
  - [Â¿QuÃ© es ChatGPT?](#quÃ©-es-chatgpt)
  - [Breve historia de los modelos de lenguaje](#breve-historia-de-los-modelos-de-lenguaje)
  - [GPT y los grandes modelos actuales](#gpt-y-los-grandes-modelos-actuales)

- [Â¿CÃ³mo funciona ChatGPT?](#cÃ³mo-funciona-chatgpt)
  - [Arquitectura basada en Transformers](#arquitectura-basada-en-transformers)
  - [GeneraciÃ³n de texto paso a paso](#generaciÃ³n-de-texto-paso-a-paso)
  - [Contexto y memoria](#contexto-y-memoria)
  - [Instrucciones del sistema y roles](#instrucciones-del-sistema-y-roles)
  - [Capacidad de adaptaciÃ³n](#capacidad-de-adaptaciÃ³n)

- [Concepto de tokens y sus lÃ­mites](#concepto-de-tokens-y-sus-lÃ­mites)
  - [Â¿QuÃ© es un token?](#quÃ©-es-un-token)
  - [Â¿Para quÃ© sirven los tokens?](#para-quÃ©-sirven-los-tokens)
  - [LÃ­mite de tokens por conversaciÃ³n](#lÃ­mite-de-tokens-por-conversaciÃ³n)
  - [Â¿CÃ³mo saber cuÃ¡ntos tokens estoy usando?](#cÃ³mo-saber-cuantos-tokens-estoy-usando)
  - [Â¿Por quÃ© es importante entender esto?](#por-quÃ©-es-importante-entender-esto)

- [Limitaciones y buenas prÃ¡cticas](#limitaciones-y-buenas-prÃ¡cticas)
  - [Limitaciones del modelo](#limitaciones-del-modelo)
  - [Buenas prÃ¡cticas para interactuar](#buenas-prÃ¡cticas-para-interactuar)

- [ProyecciÃ³n futura de la IA](#proyecciÃ³n-futura-de-la-ia)
  - [Aplicaciones emergentes](#aplicaciones-emergentes)
  - [DesafÃ­os y responsabilidades](#desafÃ­os-y-responsabilidades)
  - [Â¿QuÃ© podemos esperar?](#quÃ©-podemos-esperar)

## IntroducciÃ³n a ChatGPT

### Â¿QuÃ© es ChatGPT?

[ChatGPT](https://es.wikipedia.org/wiki/ChatGPT) (Chat Generative Pre-Trained Transformer) es un sistema conversacional basado en inteligencia artificial desarrollado por OpenAI. Utiliza modelos avanzados de lenguaje natural llamados **GPT (Generative Pre-trained Transformer)** para comprender, procesar y generar texto en mÃºltiples idiomas.

ChatGPT es capaz de:
- responder preguntas,
- redactar textos de todo tipo,
- generar cÃ³digo en diversos lenguajes de programaciÃ³n,
- traducir idiomas,
- resumir documentos,
- asistir en tareas acadÃ©micas y profesionales, entre muchas otras funciones.

Desde 2023, la versiÃ³n disponible en el plan **ChatGPT Plus** utiliza **GPT-4-turbo**, una variante optimizada de GPT-4 que ofrece mejor rendimiento, mayor velocidad y menor costo operativo. AdemÃ¡s, incluye acceso a herramientas como navegador web, visor de archivos, Python (para cÃ¡lculos, grÃ¡ficos, anÃ¡lisis de datos) y ediciÃ³n colaborativa con Canvas.

### Breve historia de los modelos de lenguaje

El desarrollo de ChatGPT se inscribe en la evoluciÃ³n del **Procesamiento de Lenguaje Natural (PLN)**, un Ã¡rea de la inteligencia artificial que busca enseÃ±ar a las mÃ¡quinas a comprender, interpretar y generar lenguaje humano.

#### De las reglas al aprendizaje profundo
- **DÃ©cadas de 1960-1980:** Los primeros sistemas (como ELIZA y SHRDLU) se basaban en reglas gramaticales simples y bases de datos cerradas.
- **DÃ©cadas de 1990-2000:** Se introdujeron los modelos estadÃ­sticos como los n-gramas, y algoritmos de aprendizaje automÃ¡tico como Naive Bayes y SVM.
- **AÃ±os 2010:** Aparecen los primeros modelos de **aprendizaje profundo**, como Word2Vec y las redes neuronales recurrentes (RNN), capaces de manejar relaciones mÃ¡s complejas entre palabras.

#### La revoluciÃ³n de los Transformers
- En 2017, Google presenta el paper â€œAttention is All You Needâ€, que introduce la arquitectura **Transformer**. Esta innovaciÃ³n permite entrenar modelos mÃ¡s grandes, con mejor comprensiÃ³n contextual.
- En 2018-2020 surgen modelos de lenguaje masivo como **BERT (Google)**, **GPT-2 (OpenAI)** y **T5**, que comienzan a usarse en tareas del mundo real.

#### GPT y los grandes modelos actuales
- **GPT-3 (2020):** Un modelo de 175 mil millones de parÃ¡metros que demostrÃ³ sorprendentes capacidades en redacciÃ³n, programaciÃ³n y razonamiento.
- **GPT-4 (2023):** Modelo multimodal (puede procesar texto e imÃ¡genes), mÃ¡s preciso y seguro.
- **GPT-4-turbo (finales de 2023):** VersiÃ³n mÃ¡s eficiente de GPT-4 utilizada en ChatGPT Plus. Aunque OpenAI no ha revelado su tamaÃ±o exacto, se sabe que es mÃ¡s rÃ¡pida y econÃ³mica.

En paralelo, otras empresas han desarrollado modelos competitivos como **Claude (Anthropic)**, **Gemini (Google DeepMind)**, **LLaMA (Meta)** y **Mistral**.

### **Â¿CÃ³mo funciona ChatGPT?**

ChatGPT funciona a partir de un modelo de lenguaje de gran escala entrenado para predecir texto de forma contextual. Se basa en la arquitectura **Transformer**, que utiliza un mecanismo llamado **atenciÃ³n** para analizar relaciones entre palabras, frases e ideas a lo largo de un texto.

#### Arquitectura basada en Transformers

A diferencia de las redes tradicionales, los Transformers permiten procesar mÃºltiples palabras al mismo tiempo y captar relaciones complejas sin importar la distancia entre tÃ©rminos. Esto mejora la fluidez, coherencia y profundidad de las respuestas.

- El mecanismo de **atenciÃ³n** asigna pesos a cada palabra de entrada en funciÃ³n de su relevancia para otras palabras del contexto.
- AsÃ­, el modelo no solo â€œleeâ€ de forma secuencial, sino que **comprende relaciones globales**, incluso en textos largos o preguntas complejas.

#### GeneraciÃ³n de texto paso a paso

1. **TokenizaciÃ³n**  
   El texto que ingresa se divide en pequeÃ±as unidades llamadas *tokens*. Un token puede ser una palabra completa, parte de una palabra o un sÃ­mbolo especial.  
   Ejemplo:  
   - "inteligencia artificial" â†’ `["int", "eligencia", " artificial"]`

2. **PredicciÃ³n probabilÃ­stica**  
   Para cada token generado, el modelo predice cuÃ¡l es el siguiente token mÃ¡s probable, considerando el contexto previo.  
   No â€œpiensaâ€ ni â€œbusca respuestasâ€: simplemente **predice texto coherente token por token**, usando estadÃ­sticas de millones de ejemplos previos.

3. **SelecciÃ³n del siguiente token**  
   El sistema puede elegir el token mÃ¡s probable, o usar un muestreo ponderado (para hacer la respuesta mÃ¡s creativa o diversa).

Este proceso se repite hasta completar una frase o alcanzar un lÃ­mite.

#### Contexto y memoria

ChatGPT no analiza frases de manera aislada, sino que considera el **historial de la conversaciÃ³n** dentro de una ventana de contexto (hasta 128.000 tokens en GPT-4-turbo).

- Puede recordar lo que se dijo hace varios mensajes y responder con coherencia.
- En modelos con **memoria activada**, tambiÃ©n puede guardar informaciÃ³n entre sesiones (por ejemplo, tu nombre o tus preferencias de estilo).

#### Instrucciones del sistema y roles

Al iniciar una conversaciÃ³n, ChatGPT recibe una **instrucciÃ³n oculta del sistema** (System prompt) que define su comportamiento. Esta instrucciÃ³n puede indicarle que actÃºe como tutor, programador, analista, redactor, etc.

AdemÃ¡s, el usuario puede modificar esa instrucciÃ³n para personalizar el estilo de las respuestas.

#### Capacidad de adaptaciÃ³n

ChatGPT es sensible al tono, la intenciÃ³n y el estilo de quien escribe:

- Si el usuario es informal, responde en el mismo tono.
- Si se formulan instrucciones precisas, intenta seguirlas con exactitud.
- Puede generar respuestas resumidas, detalladas, tÃ©cnicas o creativas segÃºn se le indique.

En resumen: ChatGPT analiza tokens, predice texto basado en contexto y estilo, y genera respuestas fluidas gracias a los mecanismos de atenciÃ³n y aprendizaje previo.

## Concepto de tokens

En los modelos de lenguaje como ChatGPT, el texto se procesa en pequeÃ±as unidades llamadas **tokens**.

### Â¿QuÃ© es un token?

Un [*token*](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them) es una unidad bÃ¡sica de texto que el modelo utiliza para procesar y generar lenguaje. En tÃ©rminos simples, es como un â€œtrozoâ€ de texto que el modelo entiende y manipula.

Un *token* puede ser:
- Una palabra completa: `maÃ±ana`
- Una parte de palabra: `incre`, `Ã­ble`
- Un sÃ­mbolo: `,`, `Â¡`, `?`
- Un espacio en blanco

Por ejemplo:
- â€œHola, Â¿cÃ³mo estÃ¡s?â€ se divide en tokens como: `["Hola", ",", "Â¿", "cÃ³mo", "estÃ¡s", "?"]`

> Regla general: **1 token â‰ˆ 4 caracteres** o **Â¾ de palabra en inglÃ©s**.

### Â¿Para quÃ© sirven los tokens?

Los modelos de lenguaje **no leen frases completas**. En su lugar:
- Dividen el texto en tokens.
- Procesan secuencia por secuencia.
- Calculan probabilidades del siguiente token para generar respuestas.

Tanto la **entrada del usuario** como la **respuesta del modelo** consumen tokens.

### LÃ­mite de tokens por conversaciÃ³n

Cada modelo tiene una **ventana de contexto**, que es el mÃ¡ximo nÃºmero de tokens que puede tener en cuenta en una interacciÃ³n.

| Modelo              | LÃ­mite de tokens |
|---------------------|------------------|
| GPT-3.5             | 16.000           |
| GPT-4-turbo (ChatGPT Plus) | 128.000       |

> Este lÃ­mite incluye **todo el historial de la conversaciÃ³n**, tanto lo que vos escribÃ­s como lo que responde el modelo.

Cuando se alcanza este lÃ­mite:
- ChatGPT empieza a olvidar los primeros mensajes.
- O bien, el sistema cierra automÃ¡ticamente la sesiÃ³n.

### Â¿CÃ³mo saber cuÃ¡ntos tokens estoy usando?

PodÃ©s usar esta herramienta oficial ğŸ‘‰ [Tokenizador de OpenAI](https://platform.openai.com/tokenizer)

- PegÃ¡s un texto y te dice cuÃ¡ntos tokens usa.
- Muy Ãºtil para calcular si un texto largo (como un informe o cÃ³digo) entra en una sola interacciÃ³n.

### Â¿Por quÃ© es importante entender esto?

- Si enviÃ¡s mensajes muy largos, **ChatGPT puede â€œolvidarâ€ partes anteriores** de la conversaciÃ³n.
- Para tareas como revisiÃ³n de textos, anÃ¡lisis legales o generaciÃ³n de informes, es clave dividir el trabajo en partes.
- TambiÃ©n afecta el **costo** si estÃ¡s usando la API de OpenAI (se cobra por token usado).

> ğŸ“Œ Buenas prÃ¡cticas:
> - EvitÃ¡ introducir mucho texto innecesario.
> - Si el contexto es largo, recordÃ¡ que podÃ©s resumirlo.
> - PedÃ­ resÃºmenes parciales o dividÃ­ documentos grandes por secciones.

## Limitaciones y buenas prÃ¡cticas

### **Limitaciones del modelo**  

- **Datos desactualizados**: ChatGPT no tiene acceso en tiempo real a internet, por lo que su conocimiento puede estar desactualizado. Para informaciÃ³n reciente, es recomendable contrastar con fuentes externas actualizadas.  
- **Respuestas generadas incorrectas o "alucinaciones"**: El modelo puede generar respuestas incorrectas o inventadas de manera convincente. Esto ocurre porque predice texto en funciÃ³n de patrones, sin una comprensiÃ³n real de la veracidad de la informaciÃ³n.  

### **Buenas prÃ¡cticas para interactuar**  

- **Validar informaciÃ³n tÃ©cnica**: No asumir que la respuesta es correcta sin verificarla. Contrastarla con documentaciÃ³n oficial, artÃ­culos revisados o expertos en el tema.  
- **Combinar ChatGPT con otras herramientas para mejorar resultados**: Usar ChatGPT junto con motores de bÃºsqueda, bases de datos especializadas o software especÃ­fico para obtener informaciÃ³n mÃ¡s precisa y confiable.

## ProyecciÃ³n futura de la IA

A medida que los modelos de lenguaje se expanden en capacidad y uso, su impacto en nuestras vidas seguirÃ¡ creciendo. Estas tecnologÃ­as estÃ¡n transformando sectores clave como la educaciÃ³n, la salud, la ingenierÃ­a, la atenciÃ³n al cliente y la creatividad digital.

![Un cuadro que muestra el futuro de la IA](./Imagenes/AI-future.jpg)

### Aplicaciones emergentes
Los LLM (Modelos de Lenguaje de Gran Escala) ya estÃ¡n siendo utilizados para:
- Automatizar tareas repetitivas o complejas.
- Asistir en el desarrollo de software y generaciÃ³n de contenido tÃ©cnico.
- Realizar anÃ¡lisis avanzados de grandes volÃºmenes de texto.
- Integrarse en flujos de trabajo colaborativos en empresas.

### DesafÃ­os y responsabilidades
Sin embargo, este avance trae consigo importantes desafÃ­os:
- **Sesgos en los datos**: los modelos reflejan (y a veces amplifican) prejuicios presentes en sus datos de entrenamiento.
- **DesinformaciÃ³n**: pueden generar respuestas incorrectas con un tono convincente.
- **Privacidad y uso Ã©tico**: se debate el uso adecuado de estos modelos en contextos sensibles.

La comunidad tÃ©cnica, legal y social deberÃ¡ trabajar en conjunto para establecer marcos de gobernanza y uso responsable de la IA.

### Â¿QuÃ© podemos esperar?
- Mayor integraciÃ³n de modelos multimodales (texto, imagen, audio, video).
- AmpliaciÃ³n de las ventanas de contexto (hasta millones de tokens).
- Modelos con capacidad de ejecutar acciones, interactuar con otras aplicaciones y **aprender de cada usuario** (mediante memorias personalizadas).

> En resumen: la IA generativa no es solo una herramienta mÃ¡s â€”es un cambio de paradigma en cÃ³mo accedemos, producimos y estructuramos conocimiento.

ğŸ§­ Para explorar ideas y predicciones en detalle, podÃ©s leer este artÃ­culo ğŸ‘‰ [AI Top-of-Mind for 7.16.24 â€” Our AI Future](https://medium.com/a-i-society/ai-top-of-mind-for-7-16-24-our-ai-future-07f1bd9b1e41)

---
[Inicio](./README.md) | [Anterior (1. Markdown)](./1-Markdown.md) | [PrÃ³ximo (3. IngenierÃ­a de Prompts)](./3-IngPrompts.md)