# Fundamentos de ChatGPT y conceptos clave

**Objetivo**: Comprender c√≥mo funciona ChatGPT, su estructura y los conceptos esenciales para interactuar eficazmente.

## Introducci√≥n a ChatGP

### **¬øQu√© es ChatGPT?**

[ChatGPT](https://es.wikipedia.org/wiki/ChatGPT) (Chat Generative Pre-Trained Transformer) es un modelo avanzado de lenguaje desarrollado por OpenAI que utiliza inteligencia artificial para comprender y generar texto de manera coherente. Dise√±ado para asistir en tareas como responder preguntas, generar contenido, traducir, programar y m√°s, ChatGPT interact√∫a de forma conversacional, adapt√°ndose a diversos contextos y necesidades.

#### Historia breve de los modelos de lenguaje.

El desarrollo de los [modelos de lenguaje](https://es.wikipedia.org/wiki/Modelaci%C3%B3n_del_lenguaje) est√° √≠ntimamente ligado al avance del **Procesamiento de Lenguaje Natural (PLN)**, una rama de la Inteligencia Artificial (IA) que busca permitir que las m√°quinas comprendan, interpreten y generen lenguaje humano de manera efectiva. Desde sus inicios, el [PLN](https://es.wikipedia.org/wiki/Procesamiento_de_lenguajes_naturales) ha evolucionado desde t√©cnicas estad√≠sticas b√°sicas hasta los impresionantes Grandes Modelos de Lenguaje ([LLM](https://es.wikipedia.org/wiki/Modelo_extenso_de_lenguaje)) que conocemos hoy en d√≠a.

**Los primeros modelos de lenguaje**
A mediados del siglo XX, con la llegada de la inform√°tica, el inter√©s por ense√±ar a las m√°quinas a procesar lenguaje humano tom√≥ forma. En esta etapa inicial, se desarrollaron enfoques basados en reglas, donde los sistemas utilizaban gram√°ticas y diccionarios predefinidos. Ejemplos de estos sistemas incluyen ELIZA (1966), que simulaba una conversaci√≥n terap√©utica, y SHRDLU (1972), dise√±ado para entender y responder preguntas en un entorno limitado.

Con el tiempo, las t√©cnicas estad√≠sticas comenzaron a reemplazar los enfoques basados en reglas. Durante la d√©cada de 1980 y 1990, los modelos n-gram, que predec√≠an palabras bas√°ndose en su probabilidad en relaci√≥n con las palabras anteriores, se volvieron populares. Aunque simples, estos modelos establecieron las bases para trabajos m√°s avanzados.

**Procesamiento de Lenguaje Natural y aprendizaje autom√°tico**
En el cambio de milenio, el PLN comenz√≥ a incorporar algoritmos de **aprendizaje autom√°tico**. M√©todos como las M√°quinas de Soporte Vectorial (SVM) y los clasificadores bayesianos fueron empleados para tareas como an√°lisis de sentimiento y categorizaci√≥n de texto. Sin embargo, estos enfoques requer√≠an caracter√≠sticas cuidadosamente dise√±adas a mano, lo que limitaba su escalabilidad y aplicabilidad.

El verdadero cambio ocurri√≥ con el auge del **aprendizaje profundo** en la d√©cada de 2010. Los modelos de redes neuronales, como Word2Vec (2013), introdujeron representaciones vectoriales de palabras (embeddings), lo que permiti√≥ capturar relaciones sem√°nticas entre palabras. Poco despu√©s, las redes recurrentes ([RNN](https://es.wikipedia.org/wiki/Redes_neuronales_recurrentes)) y sus variantes como LSTM y GRU mejoraron la capacidad de los modelos para manejar secuencias de texto m√°s largas.

**La era de los Grandes Modelos de Lenguaje (LLM)**
El avance decisivo lleg√≥ con la introducci√≥n de los modelos basados en **Transformers**, como el modelo Transformer original (2017). Este dise√±o, que utiliza mecanismos de atenci√≥n para procesar datos en paralelo, revolucion√≥ el PLN al superar las limitaciones de las redes recurrentes. En 2018, OpenAI present√≥ GPT (Generative Pre-trained Transformer), seguido por modelos m√°s avanzados como GPT-2, GPT-3 y GPT-4. Paralelamente, Google desarroll√≥ BERT, dise√±ado para comprender el contexto bidireccional en el texto.

Los **LLM** modernos como GPT-4 cuentan con miles de millones de par√°metros y son preentrenados en enormes corpus de datos textuales. Estos modelos han demostrado capacidades sorprendentes en traducci√≥n, generaci√≥n de texto, programaci√≥n y razonamiento, marcando un hito en el desarrollo del lenguaje computacional.

**Impacto y futuro**
Hoy en d√≠a, los modelos de lenguaje son esenciales en aplicaciones como asistentes virtuales, an√°lisis de datos y educaci√≥n. Sin embargo, tambi√©n plantean desaf√≠os √©ticos, como el sesgo en los datos y el uso indebido. A medida que avanza la IA, se espera que los LLM se integren a√∫n m√°s profundamente en nuestras vidas, cambiando c√≥mo interactuamos con la tecnolog√≠a y entre nosotros.

![Un cuadro que muestra el futuro de la IA](./Imagenes/AI-future.jpg)

Para m√°s informaci√≥n sobre el futuro de la IA leer este art√≠culo üëâ [AI Top-of-Mind for 7.16.24 ‚Äî Our AI Future](https://medium.com/a-i-society/ai-top-of-mind-for-7-16-24-our-ai-future-07f1bd9b1e41)

**Otras herramientas de IA**

![Logos de 16 herramientas de IA](./Imagenes/Herramientas-IA.png)

| Nombre de la herramienta | Descripci√≥n | Enlace al sitio oficial | Enlace a Wikipedia en ingl√©s |
|--------------------------|-------------|-------------------------|------------------------------|
| **Gemini** | Modelo de lenguaje grande multimodal desarrollado por Google DeepMind, sucesor de LaMDA y PaLM. | [Sitio oficial](https://ai.google/get-started/gemini-ecosystem/) | No disponible |
| **ChatGPT** | Asistente conversacional desarrollado por OpenAI basado en modelos de lenguaje, √∫til para responder preguntas, generar texto y ayudar en tareas espec√≠ficas. | [Sitio oficial](https://chat.openai.com/) | [Wikipedia](https://en.wikipedia.org/wiki/ChatGPT) |
| **Perplexity** | Motor de b√∫squeda conversacional que utiliza modelos de lenguaje para responder consultas con fuentes verificadas. | [Sitio oficial](https://www.perplexity.ai/) | [Wikipedia](https://en.wikipedia.org/wiki/Perplexity_AI) |
| **Runway** | Empresa estadounidense que se especializa en investigaci√≥n y tecnolog√≠as de inteligencia artificial generativa, enfocada en la creaci√≥n de productos y modelos para generar videos, im√°genes y contenido multimedia. | [Sitio oficial](https://runwayml.com/) | [Wikipedia](https://en.wikipedia.org/wiki/Runway_%28company%29) |
| **Claude** | Familia de modelos de lenguaje grandes desarrollados por Anthropic, con √©nfasis en la seguridad y controlabilidad de la IA. | [Sitio oficial](https://claude.ai/) | [Wikipedia](https://en.wikipedia.org/wiki/Claude_%28language_model%29) |
| **MidJourney** | Herramienta especializada en la generaci√≥n de im√°genes mediante texto, popular en dise√±o gr√°fico y arte digital. | [Sitio oficial](https://www.midjourney.com/) | No disponible |
| **Flux** | Modelo de texto a imagen desarrollado por Black Forest Labs, que genera im√°genes a partir de descripciones en lenguaje natural. | [Sitio oficial](https://blackforestlabs.ai/) | [Wikipedia](https://en.wikipedia.org/wiki/Flux_%28text-to-image_model%29) |
| **Mistral** | Modelo de lenguaje de c√≥digo abierto que busca competir con grandes actores de IA, ofreciendo soluciones de generaci√≥n de texto. | [Sitio oficial](https://www.mistral.ai/) | No disponible |
| **Grok** | Asistente de IA integrado en plataformas como Slack, dise√±ado para la automatizaci√≥n y an√°lisis de conversaciones en equipo. | [Sitio oficial](https://slack.com/intl/en-gb/blog/news/grok-ai-assistant) | No disponible |
| **Ideogram** | Herramienta para la generaci√≥n de texto en im√°genes, como carteles o dise√±os gr√°ficos con fuentes estilizadas. | [Sitio oficial](https://ideogram.ai/) | No disponible |
| **Meta** | Empresa detr√°s de proyectos avanzados de IA como LLaMA, enfocados en la investigaci√≥n y desarrollo de modelos de lenguaje e IA generativa. | [Sitio oficial](https://about.meta.com/) | [Wikipedia](https://en.wikipedia.org/wiki/Meta_Platforms) |
| **Deepseek** | Plataforma para b√∫squeda avanzada que combina capacidades de IA y procesamiento del lenguaje natural. | [Sitio oficial](https://deepseek.io/) | No disponible |
| **Minimax** | Herramienta que ofrece soluciones de IA integradas, como chatbots y modelos personalizados para empresas. | [Sitio oficial](https://www.minimax.com/) | No disponible |
| **QvQ** | Proyecto menos conocido, posiblemente relacionado con modelos de simulaci√≥n o computaci√≥n cu√°ntica aplicada a la IA. | [Sitio oficial](https://qvq.ai/) | No disponible |
| **Luma** | Plataforma de IA para la creaci√≥n y edici√≥n de contenido en 3D, como renderizados y animaciones. | [Sitio oficial](https://lumalabs.ai/) | No disponible |
| **DALL¬∑E 3** | Modelo de OpenAI dise√±ado para generar im√°genes a partir de descripciones en texto con una calidad y precisi√≥n mejoradas. | [Sitio oficial](https://openai.com/dall-e-3) | [Wikipedia](https://en.wikipedia.org/wiki/DALL-E) |

#### C√≥mo se entrenan (procesamiento de texto masivo y aprendizaje supervisado)

El entrenamiento de los **grandes modelos de lenguaje (LLM)**, como GPT, sigue un proceso complejo que combina el procesamiento de texto masivo y t√©cnicas de aprendizaje supervisado y no supervisado.

1. **Procesamiento de texto masivo**
    Los LLM se entrenan en grandes cantidades de datos textuales provenientes de libros, sitios web, art√≠culos, foros y m√°s. Estos textos se limpian para eliminar informaci√≥n irrelevante o inapropiada, como duplicados, errores ortogr√°ficos extremos o contenido que viola est√°ndares √©ticos. Luego, el texto se tokeniza, dividi√©ndose en fragmentos peque√±os (como palabras o subpalabras) que el modelo puede procesar.

2. **Preentrenamiento no supervisado**
    El modelo comienza con un preentrenamiento en el que aprende a predecir la siguiente palabra en una secuencia de texto o a llenar palabras faltantes. Esto utiliza un enorme corpus de texto sin necesidad de etiquetas humanas. T√©cnicas como el **enmascaramiento bidireccional** (en modelos como BERT) o la predicci√≥n de la siguiente palabra (en GPT) permiten al modelo captar relaciones sem√°nticas y patrones ling√º√≠sticos.

3. **Ajuste fino (aprendizaje supervisado)**
    Tras el preentrenamiento, los modelos suelen someterse a un ajuste fino utilizando conjuntos de datos m√°s peque√±os y espec√≠ficos, etiquetados por humanos. Este paso los adapta a tareas concretas, como traducci√≥n, generaci√≥n de texto o soporte t√©cnico.

4. **Retroalimentaci√≥n humana**
    Para mejorar la calidad de las respuestas, los modelos pueden entrenarse usando **aprendizaje por refuerzo a partir de retroalimentaci√≥n humana (RLHF)**, donde evaluadores humanos clasifican las respuestas del modelo, gui√°ndolo hacia respuestas m√°s √∫tiles y precisas.

### **¬øC√≥mo funciona ChatGPT?**

ChatGPT se basa en los **Transformers**, una arquitectura de redes neuronales que utiliza un mecanismo de atenci√≥n para procesar y generar texto. Su capacidad para interpretar y responder a las entradas de los usuarios depende de su entrenamiento en enormes cantidades de datos textuales y del uso de algoritmos avanzados que priorizan el contexto y las relaciones entre palabras.

#### Generaci√≥n de texto basada en predicciones probabil√≠sticas
El n√∫cleo del funcionamiento de ChatGPT es su capacidad para generar texto previendo cu√°l ser√° la pr√≥xima palabra m√°s probable en funci√≥n del contexto. Durante el entrenamiento:  

1. **Tokenizaci√≥n**: El texto de entrada se convierte en tokens (fracciones de palabras o subpalabras). Por ejemplo, "Hola, ¬øc√≥mo est√°s?" podr√≠a dividirse en "[Hola, ,, ¬ø, c√≥mo, est√°s, ?]".  
   
2. **Asignaci√≥n de probabilidad**: El modelo calcula la probabilidad de cada posible token siguiente en funci√≥n de los tokens anteriores. Por ejemplo, despu√©s de "Hola, ¬øc√≥mo", las palabras "est√°s" o "te va" tienen altas probabilidades, pero palabras como "computadora" tienen probabilidades mucho menores.  

3. **Selecci√≥n y generaci√≥n**: El modelo elige el token m√°s probable (o una combinaci√≥n ponderada para mayor variabilidad) y lo a√±ade a la secuencia generada. Este proceso contin√∫a hasta que se alcanza una longitud deseada o un token de finalizaci√≥n.

#### C√≥mo ChatGPT interpreta las entradas de los usuarios
Cuando un usuario env√≠a un mensaje, ChatGPT procesa el texto de entrada como un todo, capturando no solo las palabras individuales, sino tambi√©n sus relaciones en el contexto. Esto se logra mediante:

- **Mecanismo de atenci√≥n**: Cada palabra de la entrada influye en las dem√°s seg√∫n su relevancia, permitiendo que el modelo entienda dependencias incluso en frases largas o complejas.
- **Contexto acumulativo**: ChatGPT considera no solo el mensaje m√°s reciente, sino tambi√©n el historial de la conversaci√≥n. Esto le permite ofrecer respuestas coherentes y relevantes en interacciones m√°s largas.

#### C√≥mo ChatGPT genera respuestas
Bas√°ndose en el contexto proporcionado, el modelo predice y genera la respuesta token por token.
- Si el usuario pregunta algo ambiguo, el modelo intenta dar una respuesta general o solicita aclaraciones.
- Si la entrada es espec√≠fica, busca patrones en su conocimiento preentrenado para proporcionar detalles precisos.

En resumen, ChatGPT utiliza c√°lculos probabil√≠sticos y el contexto proporcionado para generar texto fluido y relevante. Su dise√±o lo hace capaz de adaptarse a diferentes estilos, interpretar la intenci√≥n detr√°s de las entradas y producir respuestas √∫tiles.

## Concepto de tokens

### Definici√≥n de un token
- **Palabras, partes de palabras y caracteres especiales.**
Un [token](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them) es la unidad b√°sica de texto que los modelos de lenguaje procesan, como palabras completas, fragmentos de palabras o caracteres especiales. Por ejemplo, "programaci√≥n" puede dividirse en varios tokens dependiendo del modelo utilizado.

- **Relaci√≥n entre tokens y la longitud de las respuestas.**
La longitud de las respuestas est√° limitada por el n√∫mero total de tokens que el modelo puede procesar en una interacci√≥n, incluyendo entrada y salida. Respuestas m√°s largas utilizan m√°s tokens, reduciendo el espacio disponible para el contexto.

### L√≠mites de tokens en ChatGPT

#### ¬øPor qu√© es importante comprender estos l√≠mites?
Porque en un chat, la cantidad de tokens es limitada. En la medida en que se aproxima al l√≠mite de tokens, las respuestas pierden precisi√≥n. Cuando se alcanza el l√≠mite de tokens se debe iniciar un nuevo chat.

El l√≠mite de tokens para el modelo ChatGPT Plus con GPT-4 turbo es de 128,000 tokens por conversaci√≥n (aproximadamente 90 p√°ginas de texto). Esto incluye tanto los tokens del texto de entrada como los de salida.

#### Ejemplo pr√°ctico: c√≥mo calcular tokens
Una regla pr√°ctica √∫til es que un token generalmente corresponde a ~4 caracteres de texto en ingl√©s com√∫n. Esto se traduce aproximadamente a ¬æ de una palabra (por lo tanto, 100 tokens equivalen aproximadamente a 75 palabras).

üëâ [Tokenizador](https://platform.openai.com/tokenizer) para calcular la cantidad de tokens de un texto.

## Ingenier√≠a de prompts

### ¬øQu√© es y por qu√© es importante?

La **ingenier√≠a de *prompts*** es el proceso de dise√±ar y optimizar *prompts* que se utilizan en modelos de procesamiento del lenguaje natural (PLN), como ChatGPT, chatbots o asistentes virtuales. Esto implica crear indicaciones que sean claras, concisas y eficaces para obtener la respuesta deseada.

### T√©cnicas clave:

1. **Ser espec√≠fico:** cuantos m√°s criterios se proporcionen, m√°s espec√≠fico ser√° el resultado.
2. **Trabajar por pasos:** dividir las tareas en fragmentos peque√±os. Esto arrojar√° mejores resultados, tal como lo har√≠a un humano.
3. **Iterar y mejorar:** vuelver a trabajar las entradas edit√°ndolas para que ChatGPT mejore su propio resultado.

### Ejemplos pr√°cticos:

Ver caprpeta de prompts aqu√≠ üëâ [Prompts](https://github.com/grobiglio/IA-Tools/tree/main/Prompts)

Ver los siguientes prompts archivados:
    - [Correcci√≥n de Informe T√©cnico](https://chatgpt.com/share/6799109e-e5d4-800d-ab2c-ec7ff5d9bf2c)
    - [Informe del √°rea](https://chatgpt.com/share/67991053-a638-800d-8003-3e592b221f1b)

## Limitaciones y buenas pr√°cticas

### **Limitaciones del modelo**  

- **Datos desactualizados**: ChatGPT no tiene acceso en tiempo real a internet, por lo que su conocimiento puede estar desactualizado. Para informaci√≥n reciente, es recomendable contrastar con fuentes externas actualizadas.  
- **Respuestas generadas incorrectas o "alucinaciones"**: El modelo puede generar respuestas incorrectas o inventadas de manera convincente. Esto ocurre porque predice texto en funci√≥n de patrones, sin una comprensi√≥n real de la veracidad de la informaci√≥n.  

### **Buenas pr√°cticas para interactuar**  

- **Validar informaci√≥n t√©cnica**: No asumir que la respuesta es correcta sin verificarla. Contrastarla con documentaci√≥n oficial, art√≠culos revisados o expertos en el tema.  
- **Combinar ChatGPT con otras herramientas para mejorar resultados**: Usar ChatGPT junto con motores de b√∫squeda, bases de datos especializadas o software espec√≠fico para obtener informaci√≥n m√°s precisa y confiable.